{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a9dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:56:50 | Opt:\n",
      "22:56:50 |     allow_missing_init_opts: False\n",
      "22:56:50 |     batchsize: 1\n",
      "22:56:50 |     datapath: /mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/data\n",
      "22:56:50 |     datatype: train:ordered\n",
      "22:56:50 |     dict_class: None\n",
      "22:56:50 |     display_add_fields: \n",
      "22:56:50 |     download_path: None\n",
      "22:56:50 |     dynamic_batching: None\n",
      "22:56:50 |     hide_labels: False\n",
      "22:56:50 |     ignore_agent_reply: True\n",
      "22:56:50 |     image_cropsize: 224\n",
      "22:56:50 |     image_mode: raw\n",
      "22:56:50 |     image_size: 256\n",
      "22:56:50 |     init_model: None\n",
      "22:56:50 |     init_opt: None\n",
      "22:56:50 |     is_debug: False\n",
      "22:56:50 |     loglevel: info\n",
      "22:56:50 |     max_display_len: 1000\n",
      "22:56:50 |     model: None\n",
      "22:56:50 |     model_file: None\n",
      "22:56:50 |     multitask_weights: [1]\n",
      "22:56:51 |     mutators: None\n",
      "22:56:51 |     num_examples: 5\n",
      "22:56:51 |     override: \"{'task': 'empathetic_dialogues', 'num_examples': 5}\"\n",
      "22:56:51 |     parlai_home: /mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages\n",
      "22:56:51 |     starttime: Mar02_22-56\n",
      "22:56:51 |     task: empathetic_dialogues\n",
      "22:56:51 |     teacher_seed: None\n",
      "22:56:51 |     train_experiencer_only: False\n",
      "22:56:51 |     verbose: False\n",
      "22:56:51 | Current ParlAI commit: 8b03818eb65569c74f7053708f59e01fc6021354\n",
      "22:56:51 | Current internal commit: 8b03818eb65569c74f7053708f59e01fc6021354\n",
      "22:56:51 | Current fb commit: 8b03818eb65569c74f7053708f59e01fc6021354\n",
      "22:56:51 | creating task(s): empathetic_dialogues\n",
      "[building data: /mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/data/empatheticdialogues]\n",
      "22:56:51 | Downloading http://parl.ai/downloads/empatheticdialogues/empatheticdialogues.tar.gz to /mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/data/empatheticdialogues/empatheticdialogues.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading empatheticdialogues.tar.gz: 100%|███████| 28.0M/28.0M [00:07<00:00, 3.69MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues - - -\u001b[0;0m\n",
      "\u001b[0mI remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people, we felt like the only people in the world.\u001b[0;0m\n",
      "   \u001b[1;94mWas this a friend you were in love with, or just a best friend?\u001b[0;0m\n",
      "\u001b[0mThis was a best friend. I miss her.\u001b[0;0m\n",
      "   \u001b[1;94mWhere has she gone?\u001b[0;0m\n",
      "\u001b[0mWe no longer talk.\u001b[0;0m\n",
      "   \u001b[1;94mOh was this something that happened because of an argument?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues - - -\u001b[0;0m\n",
      "\u001b[0mWas this a friend you were in love with, or just a best friend?\u001b[0;0m\n",
      "   \u001b[1;94mThis was a best friend. I miss her.\u001b[0;0m\n",
      "\u001b[0mWhere has she gone?\u001b[0;0m\n",
      "   \u001b[1;94mWe no longer talk.\u001b[0;0m\n",
      "22:57:27 | loaded 39057 episodes with a total of 64636 examples\n"
     ]
    }
   ],
   "source": [
    "from parlai.scripts.display_data import DisplayData\n",
    "DisplayData.main(task='empathetic_dialogues', num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf1a9a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:32:42 | building dictionary first...\n",
      "23:32:42 | No model with opt yet at: ../models/blender_pretrained(.opt)\n",
      "23:32:42 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: full,verbose: False,is_debug: False,datapath: /mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/data,final_extra_opt: ,eval_dynamic_batching: None,num_workers: 0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_steps: -1,load_from_checkpoint: True,world_logs: ,save_format: conversations,seed: None,log_keep_fields: all,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,wandb_log_model: False,teacher_seed: None,mutators: None,train_experiencer_only: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,beam_block_full_context: True,beam_length_penalty: 0.65,topk: 10,topp: 0.9,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,compute_tokenized_bleu: False,gpu_beam_blocking: False,interactive_mode: False,fp16_impl: mem_efficient,force_fp16_tokens: False,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,parlai_home: /mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages\u001b[0m\n",
      "23:32:42 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
      "--show-advanced-args False --task internal:new_reddit:presorted --datatype train:stream --numthreads 1 --batchsize 48 --num-epochs 5.0 --max-train-time -1 --validation-every-n-secs 1800.0 --save-after-valid True --validation-every-n-epochs -1 --validation-max-exs 9920 --short-final-eval True --validation-patience 0 --validation-metric-mode min --dict-build-first True --numworkers 4 --pytorch-preprocess False --pytorch-teacher-batch-sort False --batch-sort-cache-type pop --batch-length-range 5 --shuffle False --batch-sort-field text --pytorch-context-length -1 --pytorch-include-labels True --log-every-n-secs 30.0 --distributed-world-size 64 --port 61337 --dropout 0.1 --beam-size 8 --beam-min-n-best 3 --beam-min-length 10 --skip-generation False --inference beam --optimizer fused_adam --learningrate 0.0005 --gradient-clip 10.0 --adam-eps 1e-06 --betas 0.9,0.98 --weight-decay 0.01 --lr-scheduler invsqrt --warmup-updates 20000 --gpu 0 --beam-block-ngram 3 --beam-context-block-ngram 3\u001b[0m\n",
      "23:32:42 | loading dictionary from /mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/data/models/tutorial_transformer_generator/model.dict\n",
      "23:32:42 | num words = 54944\n",
      "23:32:44 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "23:32:44 | Loading existing model params from /mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/data/models/tutorial_transformer_generator/model\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'UnencryptedCookieSessionFactoryConfig' from 'pyramid.session' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparlai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainModel\n\u001b[0;32m----> 3\u001b[0m \u001b[43mTrainModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# similar to before\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mempathetic_dialogues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformer/generator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/blender_pretrained\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# initialize with a pretrained model\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzoo:tutorial_transformer_generator/model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# arguments we get from the pretrained model.\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Unfortunately, these must be looked up separately for each model.\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_truncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_truncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffn_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxlm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdict_lower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbpe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdict_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzoo:tutorial_transformer_generator/model.dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearn_positional_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# some training arguments, specific to this fine-tuning\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# use a small learning rate with ADAM optimizer\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# early stopping on perplexity\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mppl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# train at most 10 minutes, and validate every 0.25 epochs\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_train_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_every_n_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# depend on your gpu. If you have a V100, this is good\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp16_impl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmem_efficient\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# speeds up validation\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_generation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# helps us cram more examples into our gpu at a time\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_batching\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/script.py:127\u001b[0m, in \u001b[0;36mParlaiScript.main\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_args(args)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kwargs:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_args(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/script.py:92\u001b[0m, in \u001b[0;36mParlaiScript._run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_args()\n\u001b[1;32m     91\u001b[0m opt \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_from_parser_and_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/script.py:108\u001b[0m, in \u001b[0;36mParlaiScript._run_from_parser_and_opt\u001b[0;34m(cls, opt, parser)\u001b[0m\n\u001b[1;32m    106\u001b[0m script \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(opt)\n\u001b[1;32m    107\u001b[0m script\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m parser\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscript\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/scripts/train_model.py:1057\u001b[0m, in \u001b[0;36mTrainModel.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loop \u001b[38;5;241m=\u001b[39m \u001b[43mTrainLoop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m         set_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/scripts/train_model.py:379\u001b[0m, in \u001b[0;36mTrainLoop.__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m    376\u001b[0m     build_dict(opt, skip_if_built\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Create model and assign it to the specified task\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mlog()\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld \u001b[38;5;241m=\u001b[39m create_task(opt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent)\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/agents.py:479\u001b[0m, in \u001b[0;36mcreate_agent\u001b[0;34m(opt, requireModelExists)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# if we want to load weights from --init-model, compare opts with\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;66;03m# loaded ones\u001b[39;00m\n\u001b[1;32m    478\u001b[0m compare_init_model_opts(opt, opt)\n\u001b[0;32m--> 479\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m requireModelExists \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_file\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# double check that we didn't forget to set model_file on loadable model\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_file unset but model has a `load` function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/torch_generator_agent.py:533\u001b[0m, in \u001b[0;36mTorchGeneratorAgent.__init__\u001b[0;34m(self, opt, shared)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;66;03m# load model parameters if available\u001b[39;00m\n\u001b[1;32m    532\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading existing model params from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minit_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 533\u001b[0m     states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m     states \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/torch_agent.py:2074\u001b[0m, in \u001b[0;36mTorchAgent.load\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mparlai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m   2073\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PathManager\u001b[38;5;241m.\u001b[39mopen(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m-> 2074\u001b[0m     states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparlai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m states:\n\u001b[1;32m   2078\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/torch/serialization.py:795\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 795\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/torch/serialization.py:1012\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1010\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1011\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1012\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1016\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/torch/serialization.py:828\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/apex/__init__.py:13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyramid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterfaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (IAuthenticationPolicy,\n\u001b[1;32m     10\u001b[0m                                 IAuthorizationPolicy,\n\u001b[1;32m     11\u001b[0m                                 ISessionFactory)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyramid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msecurity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NO_PERMISSION_REQUIRED\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyramid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnencryptedCookieSessionFactoryConfig\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyramid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msettings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asbool\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ApexAuthSecret,\n\u001b[1;32m     17\u001b[0m                              ApexSessionSecret)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'UnencryptedCookieSessionFactoryConfig' from 'pyramid.session' (unknown location)"
     ]
    }
   ],
   "source": [
    "from parlai.scripts.train_model import TrainModel\n",
    "\n",
    "TrainModel.main(\n",
    "    # similar to before\n",
    "    task='empathetic_dialogues', \n",
    "    model='transformer/generator',\n",
    "    model_file='../models/blender_pretrained',\n",
    "    \n",
    "    # initialize with a pretrained model\n",
    "    init_model='zoo:tutorial_transformer_generator/model',\n",
    "    \n",
    "    # arguments we get from the pretrained model.\n",
    "    # Unfortunately, these must be looked up separately for each model.\n",
    "    n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\n",
    "    label_truncate=128, ffn_size=2048, embedding_size=512,\n",
    "    activation='gelu', variant='xlm',\n",
    "    dict_lower=True, dict_tokenizer='bpe',\n",
    "    dict_file='zoo:tutorial_transformer_generator/model.dict',\n",
    "    learn_positional_embeddings=True,\n",
    "    \n",
    "    # some training arguments, specific to this fine-tuning\n",
    "    # use a small learning rate with ADAM optimizer\n",
    "    lr=1e-5, optimizer='adam',\n",
    "    warmup_updates=100,\n",
    "    # early stopping on perplexity\n",
    "    validation_metric='ppl',\n",
    "    # train at most 10 minutes, and validate every 0.25 epochs\n",
    "    max_train_time=600, validation_every_n_epochs=0.25,\n",
    "    \n",
    "    # depend on your gpu. If you have a V100, this is good\n",
    "    batchsize=12, fp16=True, fp16_impl='mem_efficient',\n",
    "    \n",
    "    # speeds up validation\n",
    "    skip_generation=True,\n",
    "    \n",
    "    # helps us cram more examples into our gpu at a time\n",
    "    dynamic_batching='full',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62505f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TrainModel.help(model='seq2seq'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658f98fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Failed to parse one or more kwargs: skip_generation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparlai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DisplayModel\n\u001b[0;32m----> 2\u001b[0m \u001b[43mDisplayModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mempathetic_dialogues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/blender_pretrained\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_generation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/script.py:127\u001b[0m, in \u001b[0;36mParlaiScript.main\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_args(args)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kwargs:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_args(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/script.py:91\u001b[0m, in \u001b[0;36mParlaiScript._run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mConstruct and run the script using kwargs, pseudo-parsing them.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_args()\n\u001b[0;32m---> 91\u001b[0m opt \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_from_parser_and_opt(opt, parser)\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/params.py:1299\u001b[0m, in \u001b[0;36mParlaiParser.parse_kwargs\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror \u001b[38;5;241m=\u001b[39m _captured_error\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1299\u001b[0m     string_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs_to_str_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_args(args\u001b[38;5;241m=\u001b[39mstring_args)\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/d/Documents/virtual-companion/backend/venv/lib/python3.10/site-packages/parlai/core/params.py:1278\u001b[0m, in \u001b[0;36mParlaiParser._kwargs_to_str_args\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know what to do with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_unparsed_args \u001b[38;5;241m==\u001b[39m unparsed_args:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;66;03m# if we have converged to a fixed point with no improvements, we\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;66;03m# truly found some unreachable args\u001b[39;00m\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to parse one or more kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(new_unparsed_args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1280\u001b[0m     )\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;66;03m# We've seen some improvements on the number of unparsed args,\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;66;03m# iterate again\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m     unparsed_args \u001b[38;5;241m=\u001b[39m new_unparsed_args\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Failed to parse one or more kwargs: skip_generation'"
     ]
    }
   ],
   "source": [
    "from parlai.scripts.display_model import DisplayModel\n",
    "DisplayModel.main(\n",
    "    task='empathetic_dialogues',\n",
    "    model_file='../models/blender_pretrained',\n",
    "    num_examples=2,\n",
    "    skip_generation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed8d366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939b986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
